{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxkL6PjwsI6L"
   },
   "source": [
    "# 4주차 과제\n",
    "- 용어 정리\n",
    "- 딥러닝 강의 클론 코딩\n",
    "- 딥러닝 순전파 & 역전파 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixEtDe6_uGgI"
   },
   "source": [
    "## 1. 용어 정리\n",
    "\n",
    "다음 제시된 단어의 정의(설명)를 정리하여 작성 하세요.\n",
    "\n",
    "* 2문장 이상 작성 해 주세요. \n",
    "* 주제(단어)와 크게 벗어나지만 않는다면 정답처리 됩니다.\n",
    "* 강의 뿐 아니라 기타 레퍼런스를 참고하여 작성하셔도 됩니다. (기타 레퍼런스를 참고하신 경우, 해당 레퍼런스를 정리하여 하단에 작성해 주세요.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0lfwat8eurKZ"
   },
   "source": [
    "__(예시)__\n",
    "### 심층 신경망\n",
    ": 입력층과 출력층 사이에 여러 개의 은닉층들로 이뤄진 인공신경망이다. 심층 신경망은 일반적으로 인공신경망과 마찬가지로 복잡한 비선형 관계들을 모델링 할 수 있다. 신층신경망의 목적은 분류 및 수치예측을 하기 위함이고 이미지 트레이닝이나 문자인식과 같은 분야에서 매우 유용하게 쓰이고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y8YJNKG_v65A"
   },
   "source": [
    "### MCP 뉴런\n",
    ": 1943년 워랜 맥컬록(Warren Sturgis McCulloch)과 월터 피츠(Walter Pitts)는 처음으로 간소화된 뇌의 뉴런 개념을 (A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biopysics,5(4), 115-133)발표했습니다. 뇌의 뉴런, 신경세포를 이진 출력을 내는 간단한 논리 회로로 표현했는데, 여러 신호가 수상돌기에 도착하면 세포 내에서 통합되고, 통합된 신호가 임계값을 넘으면 축색 돌기에서 전달될 출력 신호가 생성됩니다. 이는 인공지능의 기초 뉴런 모델의 시초가 됩니다. \n",
    "\n",
    "### 퍼셉트론\n",
    ": 1957년 프랭크 로젠 블렛(Frank Rosenblatt)은 MCP 뉴런 모델을 기반으로 Perceptron 학습 개념을 발표하게 됩니다.\n",
    " 퍼셉트론은 뉴런에 입력되는 값($x_{n}$)과 입력값의 강도를 조절하는 가중치($w_{n}$), 결과($y$)를 출력할지 여부를 결정하는 활성함수($f(x)$)로 구성되어 있습니다. 뉴런에서 학습 할 때 변하는 것은 가중치인데 처음 초기화를 통해 무작위 값을 넣고, 점차 학습과정에서 일정한 값을 수렴하게 됩니다. 1986년 다층퍼셉트론을 활용하게 되면서 선형 분류 판별선을 여러 개 그리는 효과를 얻음으로써 XOR 문제를 해결할 수 있게 되었습니다.\n",
    "\n",
    "### 역전파\n",
    ": 1987년 James McClelland가 쓴\n",
    "Explorations in Parallel Distributed Processing 라는 책을 통해 역전파(backpropagation) 개념이 공개 되었습니다. 이는 신경망 연구의 기나긴 암흑기를 지나 인공지능의 부활을 알리는 신호탄이 되었습니다. 다층퍼셉트론의 은닉층을 활용하게 되면 선형 불류 판별선을 여러 개 그리는 효과를 얻음으로써 XOR 연산이 되지 않는 문제를 어느 정도 해결할 수 있게 되었습다. 하지만 다층 퍼셉트론의 치명적인 단점은 파라미터 개수가 많아 지면서 적절한 가중치와 편향을 학습하는 것이 어렵다는 것입니다. 제프리 힌튼은 역전파 알고리즘을 제시하면서 이 문제를 해결하였습니다. \n",
    "역전파는 뉴런의 가중치를 효율적으로 조정하기 위해 출력값과 입력값의 연산을 거꾸로 전파하며 진행합니다. 이때 출력 값과 지도 데이터 사이에서 생기는 '오차'를 이용해 출력층에서 입력층 쪽으로 가중치를 조정하는 것입니다. 이러한 손실 함수가 최솟값일 때의 가중치로 원래의 가중치를 조정해야 하고 입력값 각각의 손실 함수 전체를 고려해야 합니다. 궁국적인 목표는 모든 입력값을 대상으로 손실 함수가 최솟값일때의 파라미터를 찾는 것입니다. 최솟값$(E)$일때 가중치 $W$를 찾는 방법은 $E$ 를 가중치 $W$ 에 관해 편미분 하는 것이 되겠습니다. 미분한 값이 0에 가까운 가중치를 찾아야 하는 것인데 이는 경사하강법에 의해 기울기 값이 0에 가까워 졌을때, 손실 함수값이 최소값 후보가 되기 때문입니다.\n",
    "\n",
    "### 강화학습\n",
    ": 강화학습은 Agent라는 존재가 환경과 상호작용하며 학습해갑니다. 이 환경에는 보상과 패널티라는 기준이 있어서 다양한 시행착오를 겪으며 그 과정에서 보상을 최대화 하는 방향으로 학습해 갑니다. Agent가 최적의 정책(Policy)을 찾기 위해서는 여러 상황에서 다양한 행동을 하며 많은 경험을 하는 것이 필수입니다. 마코프 결정 프로세스는 순차적으로 계속 행동을 결정해야하는 문제를 수학적으로 정의했습니다. 강화학습은 에이전트(agent), 환경(environment), 상태(state), 행동(action), 관측 (observation), 보상(reward)의 개념을 사용하여 이해할 수 있습니다\n",
    "\n",
    "\n",
    "### 과적합\n",
    ": 학습 모델이 training data에서는 성능이 뛰어나지만 실제 데이터나 test data에서는 정확도가 떨어지는 것을 말합니다. training data에 과적합하게 되면 일반화 성능이 떨어지게 됩니다. 수학적으로 과대적합해 학습될 경우 분산이 높아지고 과소적합된 경우에는 편향이 높아지게 됩니다. 에러율이 가장 적은 모델, 즉 최적의 모델은 분산과 편향이 균형을 이룬 모델이라고 할 수 있습니다.\n",
    "\n",
    "### 차원의 저주\n",
    ": 데이터 학습을 위해 차원이 증가하면서 학습데이터 수가 차원의 수보다 적어지게 되면서 성능이 저하되는 현상을 말합니다. 설명 변수가 하나인 훈련 데이터는 1차원의 특징공간을 가졌다고 할 수 있습니다. 설명변수가 늘어 날수록 N차원의 공간을 가지게 됩니다. 우리가 겪는 차원은 기껏해야 3차원 정도 이지만, 머신러닝 학습 데이터를 살펴보면 이미지를 넘어 영상데이터를 학습하기도 합니다. 이런 데이터가 가진 차원은 화소수가 더 선명해질수록 더 큰 차원을 가지게 됩니다. 픽셀 하나 하나가 설명변수가 되는 것입니다. 이러한 문제를 차원의 저주라고 하는데 차원이 깊을 수록 학습 훈련시간이 느려지고 최적화 과정이 어렵게 됩니다. 차원이 깊어질 수록 전체 공간에서 데이터가 차지하는 공간이 매우 미비해지게 되어 예측이 불안정해 집니다. 이를 해결하기 위해 훈련데이터의 양과 크기를 키우는 것인데 데이터가 무한정 많지 않는 이상 어려운 방법입니다. 그래서 차원축소 방법으로 PCA(주성분분석)을 적용하기도 합니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d-zfFXLCy6jD"
   },
   "source": [
    "## 2. 딥러닝 강의 클론 코딩\n",
    "\n",
    "#### __퍼셉트론 구조 구현하기__ \n",
    "딥러닝 강의(__딥러닝 원리[1] 3:15 ~ 5:15 부분__)를 보고 코드를 따라 치며 출력 결과를 만드세요.\n",
    " \n",
    "\n",
    "* 하나의 코드셀에 해당 코드를 한번에 다 적어서 실행해주세요 (__그렇게 하지 않을 경우, 아래 이미지와 같은 출력값이 나오지 않을 수 있습니다__)\n",
    "\n",
    "*__주의!__ 실제로 코딩해서 출력해보면 강의에 나온 출력 결과와 다르게 나옵니다!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "aj35BSO3G84C",
    "outputId": "d82a335e-3e45-4242-b3fe-7068ec8468c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47477188589261\n",
      "학습 횟수: 99 Error: -0.053652590237368715 예측 결과: 0.053652590237368715\n",
      "학습 횟수: 199 Error: -0.026336791081233935 예측 결과: 0.026336791081233935\n",
      "학습 횟수: 299 Error: -0.017365393047355734 예측 결과: 0.017365393047355734\n",
      "학습 횟수: 399 Error: -0.01293390756830788 예측 결과: 0.01293390756830788\n",
      "학습 횟수: 499 Error: -0.010297758841233136 예측 결과: 0.010297758841233136\n",
      "학습 횟수: 599 Error: -0.008551418788821888 예측 결과: 0.008551418788821888\n",
      "학습 횟수: 699 Error: -0.007310085817846039 예측 결과: 0.007310085817846039\n",
      "학습 횟수: 799 Error: -0.006382660393380912 예측 결과: 0.006382660393380912\n",
      "학습 횟수: 899 Error: -0.005663599384350729 예측 결과: 0.005663599384350729\n",
      "학습 횟수: 999 Error: -0.005089855308167275 예측 결과: 0.005089855308167275\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.set_random_seed(2020)\n",
    "x = 1\n",
    "y = 0\n",
    "w = tf.random.normal([1], 0, 1)  # 가중치를 무작위로 선정\n",
    "b = tf.random.normal([1], 0, 1)  # 편향 무작위 선정 (난수)\n",
    "\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + math.exp(-x))\n",
    "\n",
    "output = sigmoid(x * w)\n",
    "print(output)\n",
    "\n",
    "for i in range(1000):\n",
    "    output = sigmoid(x * w + 1 * b)\n",
    "    error = y - output\n",
    "    w = w + x * 0.1 * error # 경사하강법 : 0.1 = 학습률 하이퍼 파라미터 \n",
    "    b = b + 1 * 0.1 * error \n",
    "    \n",
    "    if i % 100 == 99:\n",
    "        print(\"학습 횟수:\",i , \"Error:\", error, \"예측 결과:\", output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wcc5mzI9oZ7r"
   },
   "source": [
    "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0cceeed0-0235-4b0f-af88-0b8c377d5b4b%2F_2020-06-09__9.35.23.png?table=block&id=88fd8912-9356-49a4-9fda-a1a63fe96ea9&width=2870&cache=v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kr0HVRk8fOom"
   },
   "source": [
    "## 3. 딥러닝 순전파 & 역전파 계산\n",
    "\n",
    "딥러닝 강의(__딥러닝 원리[2] 0:55 ~ 4:32 부분__)에 나오는 순전파 & 역전파 계산에 대한 문제 입니다.\n",
    "\n",
    "해당 영상과 다음 이미지를 참고하여 다음 2가지 물음에 답하세요.\n",
    "\n",
    "\n",
    "(1) 학습률이 0.2 일 경우 출력층의 노드값\n",
    "\n",
    "(2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CpwPFWhOUzww"
   },
   "source": [
    "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff54dfd45-92ec-44ae-9616-6949d2484a45%2F_2020-06-10__5.22.03.png?table=block&id=ee05da89-3ceb-4ad9-a2d3-c9f68d24d1d9&width=3580&cache=v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B2OVY7w5U3CI"
   },
   "source": [
    "## (1) 학습률이 0.2 일 경우 출력층의 노드값 : 1.6\n",
    "## (2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은? : 0.1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4주차 과제.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
